{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":10950255,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nimport joblib\n\n# Load data\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T05:38:53.503656Z","iopub.execute_input":"2025-03-31T05:38:53.504149Z","iopub.status.idle":"2025-03-31T05:38:53.640301Z","shell.execute_reply.started":"2025-03-31T05:38:53.504110Z","shell.execute_reply":"2025-03-31T05:38:53.639215Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   id  Gender        Age    Height      Weight family_history_with_overweight  \\\n0   0    Male  24.443011  1.699998   81.669950                            yes   \n1   1  Female  18.000000  1.560000   57.000000                            yes   \n2   2  Female  18.000000  1.711460   50.165754                            yes   \n3   3  Female  20.952737  1.710730  131.274851                            yes   \n4   4    Male  31.641081  1.914186   93.798055                            yes   \n\n  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n\n        TUE       CALC                 MTRANS           NObeyesdad  \n0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n1  1.000000         no             Automobile        Normal_Weight  \n2  1.673584         no  Public_Transportation  Insufficient_Weight  \n3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>family_history_with_overweight</th>\n      <th>FAVC</th>\n      <th>FCVC</th>\n      <th>NCP</th>\n      <th>CAEC</th>\n      <th>SMOKE</th>\n      <th>CH2O</th>\n      <th>SCC</th>\n      <th>FAF</th>\n      <th>TUE</th>\n      <th>CALC</th>\n      <th>MTRANS</th>\n      <th>NObeyesdad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Male</td>\n      <td>24.443011</td>\n      <td>1.699998</td>\n      <td>81.669950</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>2.000000</td>\n      <td>2.983297</td>\n      <td>Sometimes</td>\n      <td>no</td>\n      <td>2.763573</td>\n      <td>no</td>\n      <td>0.000000</td>\n      <td>0.976473</td>\n      <td>Sometimes</td>\n      <td>Public_Transportation</td>\n      <td>Overweight_Level_II</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Female</td>\n      <td>18.000000</td>\n      <td>1.560000</td>\n      <td>57.000000</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>Frequently</td>\n      <td>no</td>\n      <td>2.000000</td>\n      <td>no</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>no</td>\n      <td>Automobile</td>\n      <td>Normal_Weight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Female</td>\n      <td>18.000000</td>\n      <td>1.711460</td>\n      <td>50.165754</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>1.880534</td>\n      <td>1.411685</td>\n      <td>Sometimes</td>\n      <td>no</td>\n      <td>1.910378</td>\n      <td>no</td>\n      <td>0.866045</td>\n      <td>1.673584</td>\n      <td>no</td>\n      <td>Public_Transportation</td>\n      <td>Insufficient_Weight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Female</td>\n      <td>20.952737</td>\n      <td>1.710730</td>\n      <td>131.274851</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>Sometimes</td>\n      <td>no</td>\n      <td>1.674061</td>\n      <td>no</td>\n      <td>1.467863</td>\n      <td>0.780199</td>\n      <td>Sometimes</td>\n      <td>Public_Transportation</td>\n      <td>Obesity_Type_III</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Male</td>\n      <td>31.641081</td>\n      <td>1.914186</td>\n      <td>93.798055</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>2.679664</td>\n      <td>1.971472</td>\n      <td>Sometimes</td>\n      <td>no</td>\n      <td>1.979848</td>\n      <td>no</td>\n      <td>1.967973</td>\n      <td>0.931721</td>\n      <td>Sometimes</td>\n      <td>Public_Transportation</td>\n      <td>Overweight_Level_II</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Encode target variable with a dedicated encoder\nle_target = LabelEncoder()\ntrain['NObeyesdad'] = le_target.fit_transform(train['NObeyesdad'])\ntarget_classes = le_target.classes_  # Store target label classes\n\n# Encode other categorical variables using new LabelEncoder instances for each\ncategorical_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col])\n    # For test data, handle unseen categories by mapping them to -1\n    test[col] = test[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n\n# Feature selection\nX = train.drop(columns=['id', 'NObeyesdad'])\ny = train['NObeyesdad']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1234)\n\n# Standardize numerical features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\ntest_data = scaler.transform(test.drop(columns=['id']))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T05:40:23.414435Z","iopub.execute_input":"2025-03-31T05:40:23.414755Z","iopub.status.idle":"2025-03-31T05:40:36.351915Z","shell.execute_reply.started":"2025-03-31T05:40:23.414731Z","shell.execute_reply":"2025-03-31T05:40:36.351045Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Define models and hyperparameter grids\nmodels = {\n    'Decision Tree': (DecisionTreeClassifier(), {'max_depth': [3, 5, 10]}),\n    'Random Forest': (RandomForestClassifier(), {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 10]}),\n    'Bagging': (BaggingClassifier(), {'n_estimators': [10, 50, 100]}),\n    'Boosting': (GradientBoostingClassifier(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]})\n}\n\nbest_models = {}\n\n# Train models using GridSearchCV\nfor name, (model, params) in models.items():\n    print(f'Training {name}...')\n    grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n    grid_search.fit(X_train, y_train)\n    best_models[name] = grid_search.best_estimator_\n    print(f'Best parameters for {name}: {grid_search.best_params_}')\n    print(f'Validation Accuracy: {grid_search.best_score_}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T05:40:40.294418Z","iopub.execute_input":"2025-03-31T05:40:40.294758Z","iopub.status.idle":"2025-03-31T05:58:51.255255Z","shell.execute_reply.started":"2025-03-31T05:40:40.294732Z","shell.execute_reply":"2025-03-31T05:58:51.254163Z"}},"outputs":[{"name":"stdout","text":"Training Decision Tree...\nBest parameters for Decision Tree: {'max_depth': 10}\nValidation Accuracy: 0.8711303526842211\nTraining Random Forest...\nBest parameters for Random Forest: {'max_depth': 10, 'n_estimators': 100}\nValidation Accuracy: 0.8923273547405352\nTraining Bagging...\nBest parameters for Bagging: {'n_estimators': 100}\nValidation Accuracy: 0.8870882409406071\nTraining Boosting...\nBest parameters for Boosting: {'learning_rate': 0.2, 'n_estimators': 200}\nValidation Accuracy: 0.9034078830988322\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Generate predictions and create submission files\nfor name, model in best_models.items():\n    predictions = model.predict(test_data)\n    # Ensure predictions are within the known range\n    predictions = np.clip(predictions, 0, len(target_classes) - 1)\n    # Convert numeric predictions back to obesity category labels\n    predictions_labels = le_target.inverse_transform(predictions.astype(int))\n    submission = pd.DataFrame({'id': test['id'], 'NObeyesdad': predictions_labels})\n    submission.to_csv(f'submission_{name}.csv', index=False)\n    print(f'Submission file for {name} created.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T06:17:22.835396Z","iopub.execute_input":"2025-03-31T06:17:22.835778Z","iopub.status.idle":"2025-03-31T06:17:23.712643Z","shell.execute_reply.started":"2025-03-31T06:17:22.835749Z","shell.execute_reply":"2025-03-31T06:17:23.711627Z"}},"outputs":[{"name":"stdout","text":"Submission file for Decision Tree created.\nSubmission file for Random Forest created.\nSubmission file for Bagging created.\nSubmission file for Boosting created.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import shutil\n\n#This code just changes the names of the submission output to submit \n#Submission 1: Decision Tree\n# Copy the file while keeping the original\n#shutil.copy('submission_Decision Tree.csv', 'submission.csv')\n\n#Submission 2: Random Forest\n# Copy the file while keeping the original\n#shutil.copy('submission_Random Forest.csv', 'submission.csv')\n\n#Submission 3: Bagging\n# Copy the file while keeping the original\n#shutil.copy('submission_Bagging.csv', 'submission.csv')\n\n#Submission 4: Boosting\n# Copy the file while keeping the original\nshutil.copy('submission_Boosting.csv', 'submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T06:46:14.160617Z","iopub.execute_input":"2025-03-31T06:46:14.161001Z","iopub.status.idle":"2025-03-31T06:46:14.168903Z","shell.execute_reply.started":"2025-03-31T06:46:14.160958Z","shell.execute_reply":"2025-03-31T06:46:14.167780Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'submission.csv'"},"metadata":{}}],"execution_count":37}]}